{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982cce07",
   "metadata": {},
   "source": [
    "# ID 5059 Coursework 1\n",
    "John Belcher-Heath (jbh6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa42b20",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The task is to predict the price of a car from a subset of attributes from the Kaggle dataset.\n",
    "\n",
    "I will complete the task following the ML checklist in the book, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. which is:\n",
    "\n",
    "1. Frame the problem\n",
    "2. Get the data\n",
    "3. Explore the data\n",
    "4. Prepare the data\n",
    "5. Explore models\n",
    "6. Fine-tune models\n",
    "7. Present solution\n",
    "8. Launch/maintain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3c9e8",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "\n",
    "We want to predict the price of a car (continuos) using a small selection of attributes available to us. This makes the problem a regression problem.\n",
    "\n",
    "Since this is a regression problem the standard performance measure of Root Mean Square Error (referred to as RMSE from now on) will be used:\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n(y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "For this measure we are looking for low RMSE. This will mean small residuals and the model is a good fit for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60086da9",
   "metadata": {},
   "source": [
    "# 2. Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64746763",
   "metadata": {},
   "source": [
    "In this section a random sleection of entries from one of the large datasets will be obtained and read into a pandas.dataframe to explore. A random selection of the large dataset will be explored since all we are doing is getting to know the data. Having a large amount of data to explore will be time consuming, but having too small (and non random sample) will mean our observations may not be valid. Taking a random sample of a large dataset should give a relatively good representation of the overall dataset, whilst minimising the amount of data requiring to be manipulated.\n",
    "\n",
    "Note when it comes to applying the model I will include a check of the data to make sure our observations on the smaller dataset still hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy pandas matplotlib scikit-learn | grep -v 'already satisfied'\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path: str = \"/cs/studres/ID5059/Coursework/Coursework-1/data/2_medium\" # uni\n",
    "folder_path : str = r\"/home/johnbh/personal_git/ID5059_coursework_1/data/3_large\" # Desktop\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    raise FileNotFoundError\n",
    "os.chdir(folder_path)\n",
    "\n",
    "file_names : list = [i for i in glob.glob(\"*.{}\".format('csv'))]\n",
    "\n",
    "    \n",
    "def read_car_data(filepath : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a filepath and returns the dataframe\n",
    "    :param filepath: The location of the file to read\n",
    "    :return: returns the pandas dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filepath, index_col = \"vin\")\n",
    "\n",
    "frac: float = 0.6 # fraction of data to use to explore\n",
    "original_df: pd.DataFrame = read_car_data(file_names[0])\n",
    "df: pd.DataFrame = original_df.sample(frac = frac)\n",
    "sample_size: int = len(df)\n",
    "\n",
    "# Clear the maximum number of columns to be displayed, so that all will be visible.\n",
    "pd.set_option('display.max_columns', None)\n",
    "# check data looks roughly okay\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5ccd2",
   "metadata": {},
   "source": [
    "# 3. Explore the data\n",
    "\n",
    "The data will now be inspected to explore what attributes are available to using the info output. Attributes with large proportion of NAs can start to be identified as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb85c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = df.reset_index(drop=True) # Reindex to make elements easier to quickly access\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674a45e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore attributes\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a004f2b",
   "metadata": {},
   "source": [
    "Initial observations from head:\n",
    "\n",
    "- A lot of measurements contain the units, making the non-numerical\n",
    "- Descriptions contain lots of irrelevant information\n",
    "- A few columns seem to represent the same information\n",
    "- Some attributes appear to have lots of NaNs\n",
    "- Multiple ID attributes which can all be dropped\n",
    "- `major_options` is a list which will need parsing somehow\n",
    "- `power` contains all the info of `horsepower`\n",
    "- Lots of irrelevant metadata to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_train: float = 0.6# fraction of data to use to explore\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size = split_train, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb5e2c",
   "metadata": {},
   "source": [
    "### Start to inspect\n",
    "Firstly, let's drop all attributes from above which have less than 50% non-null values, since including these may negatively effect our model if a majority of entries do not have this attribute. Using them in our model will mean the model is not very general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ddec30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop all attributes with less than 50% non-null values\n",
    "df = df.drop(columns=df.keys()[df.count() / sample_size < 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c377163",
   "metadata": {},
   "source": [
    "### Data types correction\n",
    "Some of the attributes appear to have been imported with different datatype, for example `zip code` as `object` not `int64`. This will be due to some integer attributes containing `NaNs`, and since the system has no interpretation for `NaNs` in `integer` types, they are taken as `object` data types instead. \n",
    "\n",
    "To further inspect this, all `object` data types are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd9c95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=object).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676cbe56",
   "metadata": {},
   "source": [
    "From manual inspection there are some attributes that need further inspection to check they have been given the correct type. The first 5 entries are shown below to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac73142",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.select_dtypes(include=object).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f9b38",
   "metadata": {},
   "source": [
    "The only attribute that can be directly converted to an integer is the `dealer_zip`, this is unlikely to provide any additional information that the `lattitude` and `longitutde` will not already give so no need to convert.This is dropped from our dataset below. \n",
    "\n",
    "This inspection has shown that a lot of the measurements have had units included, so these attributes will need to be converted to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c406eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dealer_zip\n",
    "try:\n",
    "    df = df.drop(columns='dealer_zip')\n",
    "except KeyError:\n",
    "    print(\"Column already dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb76592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_measurement(s: str) -> float:\n",
    "    \"\"\"\n",
    "    Converts the measuremnt with units to a numerical value\n",
    "    :param s: string measurement\n",
    "    :type s: str\n",
    "    :return: the actual numerical value\n",
    "    \"\"\"\n",
    "    if type(s) == str:\n",
    "        s_split: list = s.split(\" \")\n",
    "        try:\n",
    "            return float(s_split[0])\n",
    "        # If cannot convert to dtype, ie NA then return NA\n",
    "        except ValueError:\n",
    "            return float('NaN')\n",
    "    # If already converted to correct format, ie if function accidently run twice\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "cols_to_convert: list = [\"back_legroom\", \"front_legroom\", \"fuel_tank_volume\", \"height\", \"length\", \n",
    "                         \"maximum_seating\", \"wheelbase\", \"width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get numerical data from the string measurements\n",
    "df[cols_to_convert] = df[cols_to_convert].applymap(convert_measurement)\n",
    "df[cols_to_convert] = df[cols_to_convert].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c944903",
   "metadata": {},
   "source": [
    "It is important to note that the attributes power and torque contain numerical data, but this cannot be simply convert at this point but will be saved for later.\n",
    "\n",
    "Next, let's drop all the irrelevant meta data which won't be helpful with our model and will instead just increase the complexity which could lead to overfitting. For example the `description`, `interior color`, `exterior color` etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd849e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['description', 'interior_color', 'exterior_color', \n",
    "                      'main_picture_url', 'model_name', 'sp_name', 'transmission_display',\n",
    "                      'trim_name', 'trimId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b57844",
   "metadata": {},
   "source": [
    "### Fixing duplicates part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339cac0",
   "metadata": {},
   "source": [
    "It is easy to see that `engine_cylinders` and `engine_type` appear to be duplicate. Similarly so do `wheel_system` and `wheel_system_display`, as well as `make_name` and `franchise_make`.\n",
    "\n",
    "Before dropping one of each of these, the data will be further inspected to make sure that there's no discrepancy between the two in the wider data set (i.e. not just in the head)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engine = df[['engine_cylinders', 'engine_type']]\n",
    "df_engine[np.logical_xor(df_engine.engine_cylinders.isna(), df_engine.engine_type.isna())].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e80067",
   "metadata": {},
   "source": [
    "So above tells us that all entries with attributes are identical in being either NA or not, so dropping one of these attributes means no information is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e8b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='engine_cylinders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1235f274",
   "metadata": {},
   "source": [
    "For the `wheel_system` and `wheel_system_display`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc477a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_wheel = df[['wheel_system', 'wheel_system_display']]\n",
    "df_wheel[np.logical_xor(df_wheel.wheel_system.isna(), df_wheel.wheel_system_display.isna())].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86c5f3",
   "metadata": {},
   "source": [
    "The above implies that both attributes provide the same information for the cars. Hence deciding which to drop is irrelevant. I will choose to drop the `wheel_system_display` since wheel system has a nice short appriviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20343320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='wheel_system_display')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c0eb2",
   "metadata": {},
   "source": [
    "Finally for make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_make = df[['make_name', 'franchise_make']]\n",
    "df_make[np.logical_xor(df_make.make_name.isna(), df_make.franchise_make.isna())].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3add77e",
   "metadata": {},
   "source": [
    "From this we can see that the `make_name` has more information than the `franchise_make`, hence the `franchise_make` is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='franchise_make')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad8fa8",
   "metadata": {},
   "source": [
    "### Fixing duplicates part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cc41b",
   "metadata": {},
   "source": [
    "For part 2, these duplicates data may need to be extracted then compared, before just dropping attributes.\n",
    "\n",
    "Let's inspect the engine data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[np.logical_xor(df.engine_displacement.isna(), df.horsepower.isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480b0a6",
   "metadata": {},
   "source": [
    "So, luckily `horsepower` and `power` do give the same information so one can be dropped arbitrarily. As horsepower is already numerical, `power` will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b26678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### could add RPM attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deeb060",
   "metadata": {},
   "source": [
    "There is also another useful attribute of RPM which could help to distinguish between performance cars with large horsepower and 4x4 with the same, but there may be too many NAs for this attribute to use this metric, let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.horsepower.isna() / sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87118ac",
   "metadata": {},
   "source": [
    "So from above we can see that only around 5% have no `horsepower` attribute. For these remaining entries we will consider how many have engine size attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df['horsepower'].isna() & df['engine_type'].isna())]) / sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21553600",
   "metadata": {},
   "source": [
    "Now there is only a small amount of cars with neither `horsepower`, `power` or `engine_type` attribute. All these entries will simply take the overall average for `horsepower`.\n",
    "\n",
    "The `horsepower` for all cars will be assigned using the following:\n",
    "\n",
    "- if the car has `horspower` asigned pass\n",
    "- elif the car has `engine_type` assign average for that type\n",
    "- else assign the overall average for `horsepower`\n",
    "\n",
    "Let's do the first to steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['horsepower']] = df[['horsepower', 'engine_type']].groupby('engine_type').transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb21fa",
   "metadata": {},
   "source": [
    "Let's examine the improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed63eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.horsepower.count() / sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a221cac",
   "metadata": {},
   "source": [
    "Now for the final step of assigning the last na just the average of all the horsepowers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1926a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(df[['horsepower']])\n",
    "\n",
    "df[['horsepower']] = imputer.transform(df[['horsepower']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e6a42",
   "metadata": {},
   "source": [
    "Let's see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.horsepower.count() / sample_size, df.horsepower.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f67186",
   "metadata": {},
   "source": [
    "Everything looks all good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c389ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_data(s: str):\n",
    "    \"\"\"\n",
    "    Returns the hp and RPM from the power string\n",
    "    attribute of a vehicle\n",
    "    \"\"\"\n",
    "    if not pd.isna(s):\n",
    "        try:\n",
    "            string_split: list = s.split(\" \")\n",
    "            return string_split[0], string_split[3].replace(\",\", \"\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return np.nan, np.nan\n",
    "\n",
    "# Example of usage\n",
    "#zip(*map(get_power_data, df.engine_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9f578",
   "metadata": {},
   "source": [
    "### Object type attributes\n",
    "Now we have removed some of the duplicates and corrected some of the data type issues the `object` type attributes will be properly explored now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=object).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347a507",
   "metadata": {},
   "source": [
    "First let's see if any of the attributes have any blaring issues with NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b53ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=object).count() / sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b3b8a",
   "metadata": {},
   "source": [
    "Clerly some of the attributes are not suitable to use since they have a low number of entries. Any object attributes with less than 80% entries are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=df.select_dtypes(include=object).loc[:, df.select_dtypes(include=object).count() / sample_size < 0.8].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80c1e0",
   "metadata": {},
   "source": [
    "This leaves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95142e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=object).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fce31",
   "metadata": {},
   "source": [
    "Since we have `daysonmarket` attribute the `listed_date` can be dropped. Additionally, `city` can assumed to have minimal effect since most cities can be assumed to have a diverse range of individuals with varying wealth and cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['city', 'listed_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f736c8e",
   "metadata": {},
   "source": [
    "`torque` could be useful but there is too few entries (see below) for it and it is not recorded elsewhere (like `horsepower` recorded in `power` and `engine_size`). Hence I will not use this attribute for my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00811b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.torque.count() / sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='torque')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241eaf8b",
   "metadata": {},
   "source": [
    "For major options, since there is so much variabilty from visual inspection of naming of products, the number of major of features will be used instead. The actual usefulness of this will be explored later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b38de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.major_options = df.major_options.apply(lambda x: len(x.split(\",\")) if type(x) == str else \"NaN\").astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858a3ea",
   "metadata": {},
   "source": [
    "For the remaining attributes, these will be used as categorical attributes in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b49378",
   "metadata": {},
   "source": [
    "### Exploring the numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493d7be",
   "metadata": {},
   "source": [
    "Now the qualitative attributes have been dealt with it's time for the quantiative attributes.\n",
    "\n",
    "Let's explore all the numerical attributes with an actual numerical meaning(index or listing_id have no meaning numerically). Attributes with no numerical meaning our dropped below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5357688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inspection to see which numerical but non-relevant attributes need to be dropped\n",
    "df.select_dtypes(include=[np.int64, np.float64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2cf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "df_numerical = df.select_dtypes(include=[np.int64, np.float64]).drop(columns=['listing_id', 'sp_id'])\n",
    "df_numerical.hist(figsize=(16,20), bins=30)\n",
    "mpl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d778a9db",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Both Fuel economy attributes appear to be normally distributed with a slight skew\n",
    "- Majority of cars do not stay on the market for a long duration, mostly less than a couple of months. Some may be above a large amount so these may need to be removed to not skew data.\n",
    "- Engine displacement doesn't appear to have any obvious standard distribution\n",
    "- Horsepower appears to have a normal distribution around 200hp with a standard deviation of around 50hp\n",
    "- Lattitude is as expected all grouped together around 39 to 44 \n",
    "- longitutde is split into two peaks, most likely corresponding to central US and alaska\n",
    "- Milegae of most cars is grouped mostly around 0 and fewer cars with higher mileage, as would be expected\n",
    "- owner count has a modal of 1, again as to be expected\n",
    "- Most cars prices are group around the same order of magnitutde. Howeever some extremes are seen. A logarithmic transformation may need to be considered later.\n",
    "- Seller ratings appear to be skew negatively towards the higher end\n",
    "- Majority of cars are from the last 15 years\n",
    "- Modal max seats is 5\n",
    "\n",
    "It is clear as well that some of the bins are very sparse so will need coarser bins with labels for our model later to make sure our training set and test set have similar distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd11af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=[np.float64, np.int64]).count() / sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c9caf",
   "metadata": {},
   "source": [
    "Firstly it is clear to see there is no issue with NAs in the attributes: `daysonmarket`, `lattitude`, `longitude`, `price`, `savings_amount` and `year` (as well as `horsepower` after the fix above). Using contextual knowledge all these attributes (excl `price` as this is being compared to) will likely be useful in predicting the `price` attribute so will be used. \n",
    "\n",
    "Looking at the list of other attributes available with a low number of non-nulls. The additional attributes I believe may effect the `price` and want to explore more are:\n",
    "\n",
    "- `city_fuel_economy` and `highway_fuel_economy` - useful metric of car performance, more powerful and expensive cars likely to have lower fuel efficiency\n",
    "- `fuel_tank_volume` - bigger more expensive cars likely to have a large fuel tank, hence useful metric\n",
    "- `engine_displacement` and `horsepower` (and `power` which will be used to get na values) - all similar/the same metrics for how powerful a car is\n",
    "- `major_options` - more expensive cars tend to have more options\n",
    "- `mileage` - more miles done the less it is valued generally\n",
    "- `seller_rating` - If a seller has a better rating people may pay more than if they were to go to a seller with a poor rating.\n",
    "- `length` and `width` - A measure of the size of the car. Large cars tend to be more expensive. E.g. sports cars are very wide generally.\n",
    "\n",
    "I have chosen not to include `owner_count` since there are too few entries for this attribute.\n",
    "\n",
    "To explore these options there is some transformation required to remove any skew by the extreme values, also to reduce the complexity of the model.\n",
    "\n",
    "### Attribute transformation\n",
    "From the graphs above some attributes we have chosen to explore further need transforming so that the distribution of the training set and test set are similar. To do this the function below will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdbbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEED TO TWEAK\n",
    "def transform_bins(pds: pd.Series, bins, min_val = None, max_val = None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Function to transform a continuous series with sparse data to a categorical attribute with full bins.\n",
    "    The absolute max is always 0 and inf to make sure all data is captured.\n",
    "    :param pds: original cts data\n",
    "    :param bins: number of bins in resultant series (note this is how many will be attempted to be created)\n",
    "    :min_val: starting value for main section of the bins\n",
    "    :max_val: ending value for main section of the bins\n",
    "    :return: transformed series\n",
    "    \"\"\"\n",
    "    bins -=1\n",
    "    if min_val is not None and max_val is not None: \n",
    "        cuts: list = np.append(np.linspace(min_val, max_val, bins), np.array([np.inf])).tolist()\n",
    "        cuts.insert(0,0)\n",
    "    else:\n",
    "        cuts: list = np.append(np.linspace(pds.quantile(0.025), pds.quantile(0.975), bins), np.array([np.inf])).tolist()\n",
    "        cuts.insert(0, 0)\n",
    "        \n",
    "    # Drop any duplicates, ie if 0 included twice\n",
    "    cuts = list(dict.fromkeys(cuts))\n",
    "    labels: list = [str(i) for i in range(len(cuts)-1)]\n",
    "    # include_lowest needed to make sure if values are 0 they're still given a label\n",
    "    return pd.cut(pds, bins=cuts, labels=labels, include_lowest=True).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f14e531",
   "metadata": {},
   "source": [
    "The attributes needing to be transformed are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb29ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_attributes: list = [\"city_fuel_economy\", \"highway_fuel_economy\",\"daysonmarket\", \"fuel_tank_volume\", \n",
    "                              \"mileage\", \"savings_amount\", \"year\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736618f",
   "metadata": {},
   "source": [
    "The function will be applied in a uniform way with 30 bins for each first, these will then be inspected to see if more detailed transformation may be required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47086a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformed_attr: pd.DataFrame = df[transform_attributes].apply(lambda x: transform_bins(x, bins=30))\n",
    "transformed_attr.hist(figsize=(16,16))\n",
    "mpl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f402d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_attr.count() / sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0c1f8",
   "metadata": {},
   "source": [
    "These distributions look much better than before. However there may be a slight issue with `savings_amount` and `city_fuel_economy`. For this one different min, max and bins need to be used. Using contextual knowledge the following conversions are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df45a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['city_fuel_economy']] = df[['city_fuel_economy']].apply(lambda x: transform_bins(x, bins=5, min_val=18, max_val=28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['savings_amount']] = df[['savings_amount']].apply(lambda x: transform_bins(x, bins=5, min_val=100, max_val=3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[transform_attributes] = transformed_attr[transform_attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_attr.hist(figsize=(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4dd3c2",
   "metadata": {},
   "source": [
    "These look much better than before.\n",
    "\n",
    "After all the exploratory analysis a list of attributes which are hopefully correlated to the `price` attribute have been identied. But before preperation let's take a look at the correlation between the numerical attributes and the `price` to maybe eliminate some attributes, reducing the complexity \n",
    "\n",
    "### Explore correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_numerical_attributes : list = ['daysonmarket', 'latitude', 'longitude', 'price', 'savings_amount', 'year', 'horsepower', 'city_fuel_economy', \n",
    "'highway_fuel_economy', 'fuel_tank_volume', 'engine_displacement', 'major_options', 'mileage', 'mileage', 'seller_rating',\n",
    "'length', 'width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96eaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical = df.select_dtypes(include=[np.float64, np.int64])[['daysonmarket', 'latitude', 'longitude', 'price', 'savings_amount', 'year', 'horsepower', 'city_fuel_economy', \n",
    "'highway_fuel_economy', 'fuel_tank_volume', 'engine_displacement', 'major_options', 'mileage', 'mileage', 'seller_rating',\n",
    "'length', 'width', 'wheelbase']]\n",
    "# abs taken as don't care if posotive or negative effect\n",
    "corr_series = abs(df_numerical.drop(\"price\", axis=1).apply(lambda x: x.corr(df_numerical.price)))\n",
    "corr_series.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7eca33",
   "metadata": {},
   "source": [
    "Clearly some the attributes left don't have much of a correlation\n",
    "Now let's choose all attributes with a correlation of more than 0.25 and use some of our contextual knowledge to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced1279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_series[corr_series > 0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e46673",
   "metadata": {},
   "source": [
    "All these attributes seem to make logical sense. One attribute that could be removed is one of `wheelbase` or `length` since they represent different ways to measure the length of a car. Since wheelbase has the higher correlation, `length` will be dropped. Let's inspect the above attributes in more detail. Any attributes we had intially chosen but have are not included above will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4957a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_numerical_attributes = corr_series[corr_series > 0.25].keys().tolist()\n",
    "chosen_numerical_attributes.remove('length')\n",
    "chosen_numerical_attributes.append('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc72a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[chosen_numerical_attributes].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6674f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df[:, chosen_numerical_attributes], figsize=(15,15))\n",
    "mpl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014fe0b4",
   "metadata": {},
   "source": [
    "Inspecting the `price` row (or column), `horsepower` and `mileage` have the stongest correlation as to be expected. \n",
    "`wheelbase` and `width` appear to have similar correlation to price, which is to be expected by them being a measurement of size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce4f56",
   "metadata": {},
   "source": [
    "## 4. Prepare data\n",
    "### Dealing with NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e7c37",
   "metadata": {},
   "source": [
    "### Test distributions\n",
    "Let's compare the training set and test set distributions to check. All NAs will be dropped for this since the function will not work otherwise. Note this is valid since we can assume that both sets should have a similar amount of NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab832db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "shuffled_data = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=314)\n",
    "\n",
    "attr_dist_change: list = ['city_fuel_economy', 'highway_fuel_economy', 'year']\n",
    "\n",
    "results: dict = {}\n",
    "    \n",
    "for attr in attr_dist_change:\n",
    "    # Sample for all these new distributions created to see any problems\n",
    "    [(train_index, test_index)] = shuffled_data.split(df, df[attr])\n",
    "    stratified_train_set = df.loc[train_index]\n",
    "    stratified_test_set = df.loc[test_index]\n",
    "\n",
    "    train_make_up = stratified_train_set[attr].value_counts() / len(stratified_train_set)\n",
    "    test_make_up = stratified_test_set[attr].value_counts() / len(stratified_test_set)\n",
    "    results[attr] = train_make_up - test_make_up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f748e8b",
   "metadata": {},
   "source": [
    "Now all the qualitative data which was numeric has been converted. Only the categorical data will be left, this can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb96dd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=object).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33374e29",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=object).count() / sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb32bc8f",
   "metadata": {},
   "source": [
    "Clearly there is severe issues with 'owner_count'. Now this could be an important metric, however the 'mileage' attribute will likely be able to show similar information implicitly, but with likely more detail since it is a continuous not descrete attribute. Hence the owner_count will be ommitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='owner_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91530956",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d20f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, (df.count() / len(df.index)) < 0.95]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f01d5",
   "metadata": {},
   "source": [
    "As most a large amount of the attributes are categorical or boolean, changing the remaining NAs to the average of the column would not make much sense. Furthermore, since the dataset is very large, removing NAs is unlikely to heavily impact the model. However to make sure the one type of car or manufactor is not being discrimanted against before they're removed the entries with NAs will be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097501ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_makes_with_NA = df1[df1.isnull().any(axis=1)].make_name.unique()\n",
    "df_prepared = df1[~df1.isnull().any(axis=1)]\n",
    "car_makes_no_NA = df_prepared.make_name.unique()\n",
    "\n",
    "(set(car_makes_no_NA) and set(car_makes_with_NA)) == set(car_makes_with_NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408d079",
   "metadata": {},
   "source": [
    "This means all car makes are being represented still even when NA rows are removed.\n",
    "\n",
    "Now the data has been filtered, the exploration of relationships can begin. Note that only 4% of the entries have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(len(df_prepared.index) / data_original_length, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_prices = df_prepared[\"price\"].copy()\n",
    "used_cars_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(folder_path)\n",
    "# file_names : list = [i for i in glob.glob(\"*.{}\".format('csv'))]\n",
    "# df = pd.concat(map(read_car_data, file_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746131ba",
   "metadata": {},
   "source": [
    "## Choosing attributes\n",
    "\n",
    "Inspecting this list and using our contextual knowledge of cars, as well as the info available on the [kaggle page](https://www.kaggle.com/datasets/ananaymital/us-used-cars-dataset). Certain attributes can be removed immediately, leaving ones that are believed to influence the price. Any attributes left will be further inspected before any models are used. \n",
    "\n",
    "Note: data types are now defined to make sure any further exploration is done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178102a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes belived to influence price\n",
    "desired_attributes : list = [\"body_type\", \"city\", \"daysonmarket\", \"dealer_zip\", \"engine_cylinders\", \"engine_displacement\",\n",
    "                             \"engine_type\", \"fleet\", \"frame_damaged\", \"franchise_dealer\", \"fuel_tank_volume\", \"has_accidents\", \"horsepower\",\n",
    "                            \"is_new\", \"listed_date\", \"make_name\", \"owner_count\", \"power\", \"price\",\n",
    "                             \"savings_amount\", \"seller_rating\", \"year\", \"torque\"\n",
    "                            ]\n",
    "    \n",
    "# REMOEVE ANY IRRELEVANT ONES\n",
    "# Define datatypes of attributes to make sure any exploration is good.\n",
    "data_types = {'vin' : str, 'back_legroom' : str, 'bed' : str, 'bed_height' : str,\n",
    "              'bed_length' : str, 'body_type' : str, 'cabin' : str, 'city' : str,\n",
    "              'city_fuel_economy' : np.float64, 'combine_fuel_economy' : np.float64,\n",
    "              'daysonmarket' : np.int32, 'dealer_zip' : np.int32, 'description' : str, \n",
    "              'engine_cylinders' : str, 'engine_displacement' : np.float64,\n",
    "              'engine_type' : str, 'exterior_color' : str, 'fleet' : bool, 'frame_damaged' : bool,\n",
    "              'franchise_dealer' : bool, 'franchise_make' : str, 'front_legroom' : str,\n",
    "              'fuel_tank_volume' : str, 'fuel_type' : str, 'has_accidents' : bool, 'height' : str,\n",
    "            'highway_fuel_economy' : np.float64, 'horsepower' : np.float64, 'interior_color' : str, 'isCab' : bool,\n",
    "            'is_certified' : bool, 'is_cpo' : bool, 'is_new' : bool, 'is_oemcpo' : bool, 'latitude' : np.float64, 'length' : str,\n",
    "            'listed_date' : str, 'listing_color' : str, 'listing_id' : np.int32, 'longitude' : np.float64,\n",
    "            'main_picture_url' : str, 'major_options' : str, 'make_name' : str, 'maximum_seating' : np.int32,\n",
    "            'mileage' : np.int32, 'model_name' : str, 'owner_count' : np.int32, 'power' : str, 'price' : np.float64, 'salvage' : bool,\n",
    "            'savings_amount' : np.int32 , 'seller_rating' : np.float64, 'sp_id' : np.int32, 'sp_name' : str, 'theft_title' : bool,\n",
    "            'torque' : str, 'transmission' : str, 'transmission_display' : str, 'trimId' : np.int32, 'trim_name' : str,\n",
    "            'vehicle_damage_category' : str, 'wheel_system' : str, 'wheel_system_display' : str,\n",
    "            'wheelbase' : str, 'width' : str, 'year' : np.int32}\n",
    "\n",
    "    \n",
    "df = df[df.columns.intersection(desired_attributes)].convert_dtypes(data_types).copy()\n",
    "df = df.reset_index(drop=True) # Let's also reset the index to stop using vin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
